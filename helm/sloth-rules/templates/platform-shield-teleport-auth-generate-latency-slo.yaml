# This file is automatically generated. Any manual changes will be wiped out.
apiVersion: sloth.slok.dev/v1
kind: PrometheusServiceLevel
metadata:
  name: platform-shield-teleport-auth-generate-latency-slo
  namespace: monitoring
  labels:
    application.giantswarm.io/team: shield
    observability.giantswarm.io/tenant: giantswarm
spec:
  service: "teleport"
  labels:
    owner: "shield"
    customer: "{{ .Values.managementCluster.customer }}"
    installation: "{{ .Values.managementCluster.name }}"
    pipeline: "{{ .Values.managementCluster.pipeline }}"
    {{- if .Values.managementCluster.region }}
    region: "{{ .Values.managementCluster.region }}"
    {{- end }}
  slos:
    - name: "auth-generate-latency-slo"
      objective: 95
      description: "95th percentile of Teleport authentication request latencies should be below the threshold"
      sli:
        events:
          errorQuery: |-
            {{`histogram_quantile(0.99, sum by (cluster_id, cluster_type, customer, installation, pipeline, provider, region) (rate(auth_generate_seconds_bucket{cluster_id="teleportprod", job="teleport/teleport-cluster"}[{{.window}}]))) > 0.2`}}
          totalQuery: |-
            {{`sum by (cluster_id, cluster_type, customer, installation, pipeline, provider, region) (rate(auth_generate_seconds_count{cluster_id="teleportprod", job="teleport/teleport-cluster"}[{{.window}}]))`}}
      alerting:
        name: "TeleportAuthGenerateLatencyHigh"
        labels:
          cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
          silence: "true"
          area: platform
          cluster_id: "{{ printf "{{ .Labels.cluster_id }}" }}"
          cluster_type: "{{ printf "{{ .Labels.cluster_id }}" }}"
          team: shield
        pageAlert:
          disable: false
          labels:
            severity: page
        ticketAlert:
          disable: false
          labels:
            severity: "notify"
            slack_channel: "#alert-shield"
