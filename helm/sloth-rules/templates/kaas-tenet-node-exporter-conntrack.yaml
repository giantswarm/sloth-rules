# This file is automatically generated. Any manual changes will be wiped out.
apiVersion: sloth.slok.dev/v1
kind: PrometheusServiceLevel
metadata:
  name: kaas-tenet-node-exporter-conntrack
  namespace: monitoring
  labels:
    application.giantswarm.io/team: tenet
spec:
  service: "node-exporter"
  labels:
    owner: "tenet"
    cluster_id: "{{ printf "{{ .Labels.cluster_id }}" }}"
    cluster_type: "{{ printf "{{ .Labels.cluster_id }}" }}"
    customer: "{{ .Values.managementCluster.customer }}"
    installation: "{{ .Values.managementCluster.name }}"
    pipeline: "{{ .Values.managementCluster.pipeline }}"
    region: "{{ .Values.managementCluster.region }}"
  slos:
    - name: "conntrack"
      objective: 85
      description: "Node Conntrack is almost exhausted"
      sli:
        events:
          errorQuery: |-
            {{`sum(count_over_time((node_nf_conntrack_entries / node_nf_conntrack_entries_limit >= 0.7)[{{.window}}:{{.window}}]))`}}
          totalQuery: |-
            {{`sum(count_over_time((node_nf_conntrack_entries)[{{.window}}:{{.window}}]))`}}
      alerting:
        name: "NodeConnTrackAlmostExhausted"
        labels:
          team: {{ include "providerTeam" . }}
          area: kaas
        annotations:
          opsrecipe: "node-conntrack-limits/"
        pageAlert:
          disable: false
          labels:
            cancel_if_cluster_status_updating: "true"
            cancel_if_outside_working_hours: "true"
            cancel_if_prometheus_agent_down: "true"
            cancel_if_cluster_status_creating: "true"
            cancel_if_cluster_status_deleting: "true"
            severity: page
            team: {{ include "providerTeam" . }}
        ticketAlert:
          disable: false
          labels:
            severity: "notify"
            slack_channel: {{ include "providerTeam" . | replace "'" "" | printf "#alert-%s" | quote }}
