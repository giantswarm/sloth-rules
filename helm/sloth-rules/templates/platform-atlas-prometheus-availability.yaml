# This file is automatically generated. Any manual changes will be wiped out.
apiVersion: sloth.slok.dev/v1
kind: PrometheusServiceLevel
metadata:
  name: platform-atlas-prometheus-availability
  namespace: monitoring
  labels:
    release: prometheus
    application.giantswarm.io/team: atlas
    cluster_type: management_cluster
spec:
  service: "prometheus"
  labels:
    owner: "atlas"
  slos:
    - name: "availability"
      objective: 90
      description: Prometheus is unavailable
      sli:
        events:
          errorQuery: |-
            sum(label_replace(avg_over_time(kube_pod_status_ready{condition="false",namespace=~"(.*)-prometheus"}[{{.window}}]), "cluster_id", "$1", "pod", "prometheus-(.+)-(.+)")) by (pod, cluster_id, cluster_type, customer, installation, pipeline, provider, region)
          totalQuery: |-
            sum(label_replace(avg_over_time(kube_pod_status_ready{namespace=~"(.*)-prometheus"}[{{.window}}]), "cluster_id", "$1", "pod", "prometheus-(.+)-(.+)")) by (pod, cluster_id, cluster_type, customer, installation, pipeline, provider, region)
      alerting:
        name: PrometheusUnavailable
        labels:
          team: atlas
          area: platform
          topic: observability
        annotations:
          dashboard: promavailability/prometheus-availability
          description: {{`Prometheus {{$labels.pod}} is unavailable.`}}
          opsrecipe: prometheus-resource-limit-reached/
        pageAlert:
          disable: false
          labels:
            cancel_if_any_apiserver_down: "true"
            cancel_if_cluster_has_no_workers: "true"
            cancel_if_cluster_status_updating: "true"
            cancel_if_outside_working_hours: "true"
            cancel_if_cluster_status_creating: "true"
            cancel_if_cluster_status_deleting: "true"
            severity: page
            team: atlas
        ticketAlert:
          disable: false
          labels:
            severity: "notify"
            slack_channel: "#team-atlas"
